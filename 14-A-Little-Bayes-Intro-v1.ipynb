{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Creative Commons CC BY 4.0 Lynd Bacon & Associates, Ltd. Not warranted to be suitable for any particular purpose. (You're on your own!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Brief Bayes Digression\n",
    "\n",
    "(_Originally prepared for the 2018 Univ. of Utah DeCART data science for health care workshop on machine learning and predictive analytics._)\n",
    "\n",
    "And now for something different.\n",
    "\n",
    "Bayesian regression in a just a few minutes.\n",
    "\n",
    "Prediction problems can be approached using Bayesian methods.  Although methods for nontrivial \"learning\" (prediction) problems can be computationally intensive, continuing advances in algorithm and hardware development are making Bayesian applications feasible in an ever-widening array of contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes Theorem\n",
    "\n",
    "It has been called the \"inverse probability\" theorem.  Attributed to the 18th century cleric Thomas Bayes, it's based on a principle of conditional probabilities:  \n",
    "\n",
    "\\begin{align*}\n",
    "\\large\n",
    "p(A|B) = \\frac{p(B|A)p(A)}{p(B)}\n",
    "\\end{align*}  \n",
    "\n",
    "Here, A and B are events of some sort that may or may not occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can see where this theorem came from by using the definition of a conditional probability:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\large {\n",
    "p(A~and~B) = p(A|B)p(B) \\\\\n",
    "P(B~and~A) = p(B|A)p(A) \\\\\n",
    "p(A~and~B) = p(B~and~A) \\\\\n",
    "p(A|B)p(B) = p(B|A)p(A) }\n",
    "\\end{align*}  \n",
    "\n",
    "\\begin{align*}\n",
    "\\large{\n",
    "p(A|B) = \\frac{p(B|A)}{p(B)} \\\\ }\n",
    "\\end{align*}  \n",
    "\n",
    "It's pretty simple.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In scientific applications, we use Greek letters to make it look more serious:  \n",
    "\n",
    "\\begin{align*}\n",
    "\\large\n",
    "p(\\theta|D)~=~\\frac{p(D|\\theta)p(\\theta)}{p(D)}\n",
    "\\end{align*}  \n",
    "\n",
    "Here, $\\theta$ is one or more parameters we want to learn about, and D is \"data,\" or information. $\\theta$ can be a very long vector. The term on the LHS is the posterior probability of $\\theta$ conditional on D; it tells us about uncertainty about $\\theta$.  The two quantities in the numerator on the RHS are referred to as the likelihood of the data given $\\theta$, and the prior probability of $\\theta$.  p(D) is often called the data density.  For a particular data set it's constant, so when estimating p($\\theta$|D) it's ignored, and the version of the above that's used is:  \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\large\n",
    "p(\\theta|D)~\\propto~p(D|\\theta)p(\\theta)\n",
    "\\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\begin{align*}\n",
    "\\large\n",
    "p(\\theta|D)~\\propto~p(D|\\theta)p(\\theta)\n",
    "\\end{align*}\n",
    "\n",
    "One way of looking at this theorem is that it is a _learning algorithm_:  \n",
    "* p($\\theta$) is what we know about parameters of interest before getting D.  \n",
    "* p(D|$\\theta$) is the likelihood of data we've observed given what we have believed about $\\theta$.\n",
    "* p($\\theta$|D) is how we've \"adjusted\" what we believe about $\\theta$ now that we've received D. \n",
    "\n",
    "p($\\theta$|D) can be our \"best guess\" about p($\\theta$) the next time we are about to get new D.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approximating p($\\theta$|D) \n",
    "\n",
    "Approximating p($\\theta$\\D) is the main objective of Bayesian modeling.  It's what we use to make inferences about $\\theta$.\n",
    "\n",
    "In any given Bayesian model, $\\theta$ may have many parameters, and p($\\theta$|D) may be highly dimensional. Many applications involve estimating so many parameters that estimating them _cannot_ be done analytically, e.g. by solving equations.  \n",
    "\n",
    "For estimation purposes, _stochastic_ simulation methods are typically used. These methods are generally called _Markov Chain Monte Carlo_ (MCMC) simulation methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here are the basic steps used when estimating a Bayesian regression model.\n",
    "\n",
    "* Specify a _full probability model_ that defines the relationships between variables, and the distributions of all parameters and functions of them. \n",
    "\n",
    "* Select a _sampling method_ that is used iteratively to obtained values from the marginal conditional posterior of each parameter that is defined in your model specification.\n",
    "\n",
    "* Define initial values for each parameter, your $\\theta$ elements, and let your algorithm run.\n",
    "\n",
    "* Each iteration of it produces a \"draw,\" a value, from the posterior of each parameter. A series of draws is called a \"chain\" or a \"trace.\"\n",
    "\n",
    "* Based on a general theory of ergodicity, given that a model's parameters are sufficiently identified in your specification, these chains of parameter value estimates will \"settle in\" to be random draws from stable, conditional posterior parameter distributions.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once you've approximated the conditional joint posterior probability distribution of model parameters, you can use it to make predictions for new data.  You can get prediction error estimates by using the new data and making random draws from  the posterior density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### But, Why?\n",
    "\n",
    "* Bayesian modeling methods can be used to estimate where it's not possible to use non-Bayesian methods. \n",
    "\n",
    "* Bayesian estimates are _shrinkage_ estimates, so that they tend to mitigate overfitting by models.  \n",
    "\n",
    "* Bayesian models can incorporate _prior knowledge_ into the estimation of parameters given data.\n",
    "\n",
    "* Hypothesis testing doesn't require relying on asymptotics as sample sizes to to infinity, or to doing thought experiments using imaginary data. \n",
    "\n",
    "* Once you've estimated parameter chains, you can use them to compute posterior distributions of _functions_ of the parameters.  \n",
    "\n",
    "* Parameters for individual observational units can be estimated even when the unit-level data are sparse due to the \"partial pooling\" of information that hierarchical models afford.\n",
    "\n",
    "* Bayesian methods provide a \"natural\" way of dealing with missing values.  You just estimate them as parameters are estimated, all together in the same simulation."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
