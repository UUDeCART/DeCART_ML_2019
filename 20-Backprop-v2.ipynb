{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Creative Commons CC BY 4.0 Lynd Bacon & Associates, Ltd. Not warranted to be suitable for any particular purpose. (You're on your own!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back-Propagation (\"backprop\") (A Digression)\n",
    "\n",
    "* _Back-propagation_ , or the \"back propagation of errors,\" is a method for estimating the _gradient_ ($\\nabla$, or \"Grad\"), the set of partial derivatives of the loss function with respect to the weights to be learned.\n",
    "    * implemented as an algorithm\n",
    "    * The dimensionality of the Grad equals the number of weights in a network.\n",
    "* You need to be able to calculate the Grad in order to use a gradient descent method.  \n",
    "* Gradient estimation is relatively straightforward for simple models like linear regression models.\n",
    "* It's more complicated for deep NN's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grad for a Simple Model\n",
    "\n",
    "For example, assuming an L2 loss function, the gradient for a conventional _regression_ model could look like \n",
    "\n",
    "\\begin{align}\n",
    "\\large\n",
    "\\frac{\\partial}{\\partial w} Loss(W) =  \\frac{\\partial}{\\partial w}\\mid y - h_w (x)\\;   \\mid^2 \\\\\n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "\n",
    "y is a vector of target, or dependent variable, values;    \n",
    "W is a vector of weights to be estimated(learned);   \n",
    "h is some activation function, possibly a linear identity \"transformation\";  \n",
    "h_w(x) is the the product of a vector of weights $h_w$ and input variables (features) __x__;  \n",
    "y - $h_w$(x) is a vector of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Gradient, and Gradient Descent\n",
    "\n",
    "* A models' **w's** (weights) can be solved for analytically if the model is a standard linear regression model:\n",
    "    * **y** is a continuous measure;\n",
    "    * The RHS of the model equation is _linear in its parameters_, e.g. for \"P\" predictor variables X<sub>p</sub>: \n",
    "    \n",
    "    $\\large {w_0+w_1 * X_1+w_2 * X_2 +...w_P*X_P}$ \n",
    "      \n",
    "  \n",
    "* L2 Loss is a quadratic function of the **w<sub>p</sub>'s**.\n",
    "* For pretty much all other model forms, a closed form analytical solution isn't available, and so _interative_ use of the gradient is what's done. In the simple, one **w** case,  \n",
    "    * Start with an initial value of **w_i**\n",
    "    * Initialize **w_i**\n",
    "    * Loop until Loss(**w**) is minimized:  \n",
    "      \n",
    "        * $\\large {w_i \\gets w_i - \\alpha  \\frac{\\partial Loss}{\\partial w_i}}$ \n",
    "        \n",
    "where:\n",
    "$\\alpha$ is the step size, or _**learning rate**_ . \n",
    "\n",
    "Note that the _negative_ of the Grad is used in order to point in the direction of decreasing Loss.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back-propagation  \n",
    "\n",
    "Because a deep NN has multiple layers of nodes, the RHS of the equation mapping real number inputs to the NN's outputs contains _multiple, embedded_ functions, where each function respresents a node, inputs, weights, and an activation function. \n",
    "\n",
    "For example, a k layer NN, output = y, input = x, h<sub>w(k)</sub> is one (or more) nodes(s) with activation function(s) h and weights w<sub>ij</sub>:\n",
    "\n",
    "\\begin{align}\n",
    "\\large {y = h_{w(k)}(h_{w(k-1)}(h_{w(k-2)}(...h_{0}(x))}\n",
    "\\end{align}\n",
    "\n",
    "The RHS is a composition of functions, and weights w<sub>ij</sub> are \"buried inside.\"  But what we want to calculate is $\\frac {\\partial Loss} {\\partial w_{ij}}$ For every w<sub>ij</sub>, regardless of where they are in the network graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Chain Rule\n",
    "\n",
    "* To deal with this, the Grad can be calculated using the _chain rule_ for differentiating embedded functions:  \n",
    "    * [chain rule on Wikipedia](https://en.wikipedia.org/wiki/Chain_rule)\n",
    "    * Application of attributed to Rumelhart, Hinton & Williams (1986), and perhaps earlier others.\n",
    "* The chain rule can be applied to a _computational graph_. \n",
    "* This allows _back propagating_ errors back though a NN.\n",
    "* As a simple example, assume a computational graph like: \n",
    "\n",
    "\\begin{align}\n",
    "\\large {f_0(w) \\to f_1(y) \\to f_2(z) \\to u}\n",
    "\\end{align}\n",
    "\n",
    "where   \n",
    "w, y, x, and u are variables;\n",
    "f<sub>0</sub>, f<sub>1</sub>, and f<sub>2</sub> are functions relating the variables.\n",
    "\n",
    "u results from _embedded functions_ f<sub>2</sub>(z), f<sub>1</sub>(y), and f<sub>0</sub>(x):\n",
    "\n",
    "\\begin{align}\n",
    "\\large\n",
    "u = f_2(f_1(f_0(x)))\n",
    "\\end{align}\n",
    "\n",
    "Appying the chain rule to get the partial derivative of u w.r.t. w:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac {\\partial u} {\\partial w} &  \\\\\n",
    "& = \\frac {\\partial u} {\\partial z} \\frac {\\partial z} {\\partial y} \\frac {\\partial y} {\\partial w} \\\\\n",
    "& = f_2'(z) f_1'(y) f_0'(w) \\\\\n",
    "& = f_2'(f_1((f_0(x)))f_1'(f_0(x))f_0'(w) \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Chain Rule As Used by Backprop Algorithms \n",
    "\n",
    "The previous chain rule example indicates getting the partial derivative of a variable **u** w.r.t. a single variable w.  NN's can of course have many, many w (weights). \n",
    "\n",
    "A NN can have a number of outputs.  For training purposes, their values can be combined with \"true\" label values and summarized into a scalar Loss measure, e.g. MSE.\n",
    "\n",
    "Applying the chain rule in the conventional form (above) to estimate all  $\\frac {\\partial Loss} {\\partial w_{ij}}$ for a NN results in a large amount of redundant computation.  Many of the same quantities would be calculated over and over again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backprop Chain Rule (cont)\n",
    "\n",
    "Backprop algorithms employ the chain rule in such a way that required quantities are calculated only once such that:  \n",
    "* the computation required scales linearly with the number of links or edges in a network graph;\n",
    "* the per edge computation includes calculating a partial derivative, a multiplication, and an addition. \n",
    "\n",
    "The quantities involved in these calculations can be scalars, vectors, or tensors.\n",
    "\n",
    "Implementations involve using a computational graph like the above, but much more complicated.  NN libraries differ in the use of such graphs. These graphs are _symbolic and algebraic_ respresentations They operate on symbols, or on variables that do not have specific values.\n",
    "\n",
    "* one approach: input numerical quantities to the graph, and return values for the gradient. (e.g. Torch, Caffe)\n",
    "* another: augment the graph with nodes calculating the required partial derivatives (Theano, Tensorflow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources\n",
    "\n",
    "For an overview of back-propagation, see:  \n",
    "\n",
    "[Back-prop summary on the \"ML Cheat Sheet\"](https://ml-cheatsheet.readthedocs.io/en/latest/backpropagation.html) \n",
    "\n",
    "References:\n",
    "\n",
    "Goodfellow et. al., _Deep Learning_. Cambridge MA: The MIT Press, 2016, pp. 197-206.\n",
    "\n",
    "Rumelhardt, et al.(1986) _Learning representations by back-propagating errors._ _Nature_, **323**, 533-536\n",
    "\n",
    "Russell, S. & Norvig, P., _Artificial Intelligence: A Modern Approach_ (3rd Ed.). Pearson India, 8th imprinting, 2017. pp. 746-749.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
